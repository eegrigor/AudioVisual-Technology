{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnwC9RidfosB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading audio files that are stored in pickle form in Google Drive\n",
        "\n",
        "# 0 linguistic family -> Greek\n",
        "with open('/content/drive/MyDrive/audio/el_npy.pickle', 'rb') as file:\n",
        "    size = 1000\n",
        "    X = np.array(pickle.load(file)[:size])\n",
        "    y = np.zeros(size-1)\n",
        "\n",
        "# 1 linguistic family -> Spanish, French\n",
        "size = 500\n",
        "with open('/content/drive/MyDrive/audio/fr_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 1))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/es_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 1))\n",
        "\n",
        "# 2 linguistic family -> English, Swedish, Norwegian, German, Dutch\n",
        "size = 200\n",
        "with open('/content/drive/MyDrive/audio/nl_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 2))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/no_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 2))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/sv_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 2))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/de_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 2))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/en_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:size], axis=0)\n",
        "    y = np.append(y, np.full(size, 2))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqV6D4pghdNa",
        "outputId": "0528ced1-9ac3-41ec-8a18-bbae030dfd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2999, 1000, 40)\n",
            "(2999,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "X,y = shuffle(X,y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X=[]\n",
        "y=[]"
      ],
      "metadata": {
        "id": "5aNT8KZ8mG68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(7, 7), activation='relu', padding='valid', input_shape=(1000,40,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(64,(5,5), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(256,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(512,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmbuboEtmIFK",
        "outputId": "10a46760-3486-4282-d9d1-466908c5ce97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 994, 34, 32)       1600      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 994, 34, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 497, 17, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 497, 17, 64)       51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 497, 17, 64)      256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 249, 9, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 249, 9, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 249, 9, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 125, 5, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 125, 5, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 125, 5, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 63, 3, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 63, 3, 512)        1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 63, 3, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 32, 2, 512)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32768)            131072    \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               8388864   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,127,747\n",
            "Trainable params: 10,059,715\n",
            "Non-trainable params: 68,032\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "adam = Adam()\n",
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.00158\n",
        "\tdrop = 0.9\n",
        "\tepochs_drop = 1\n",
        "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "\treturn lrate\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=adam,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "                'model.h5',\n",
        "                monitor='val_acc',\n",
        "                verbose=0,\n",
        "                save_best_only=True,\n",
        "                mode='max'\n",
        "                )\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "es = EarlyStopping(monitor='val_loss',mode = 'max', patience=3)\n",
        "model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                epochs=60,\n",
        "                callbacks=[checkpoint, lrate],\n",
        "                verbose=1,\n",
        "                validation_data=(X_test, y_test),\n",
        "                batch_size=16)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qi3PoO2mzaG",
        "outputId": "a9f56dc5-71de-4ec4-be46-9ffe1a9d644b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169/169 [==============================] - ETA: 0s - loss: 1.6707 - accuracy: 0.3461"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 18s 49ms/step - loss: 1.6707 - accuracy: 0.3461 - val_loss: 1.3085 - val_accuracy: 0.3600 - lr: 0.0014\n",
            "Epoch 2/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 1.3160 - accuracy: 0.3938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 1.3160 - accuracy: 0.3938 - val_loss: 1.1658 - val_accuracy: 0.4000 - lr: 0.0013\n",
            "Epoch 3/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 1.1478 - accuracy: 0.4579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 37ms/step - loss: 1.1478 - accuracy: 0.4579 - val_loss: 1.2132 - val_accuracy: 0.4000 - lr: 0.0012\n",
            "Epoch 4/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 1.0164 - accuracy: 0.5287"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 37ms/step - loss: 1.0164 - accuracy: 0.5287 - val_loss: 1.8018 - val_accuracy: 0.3933 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.6054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.8847 - accuracy: 0.6054 - val_loss: 2.3275 - val_accuracy: 0.3500 - lr: 9.3297e-04\n",
            "Epoch 6/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.7792 - accuracy: 0.6706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.7792 - accuracy: 0.6706 - val_loss: 1.3567 - val_accuracy: 0.3900 - lr: 8.3968e-04\n",
            "Epoch 7/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.7203"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.6761 - accuracy: 0.7203 - val_loss: 1.3980 - val_accuracy: 0.4433 - lr: 7.5571e-04\n",
            "Epoch 8/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7647"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.5652 - accuracy: 0.7647 - val_loss: 3.4407 - val_accuracy: 0.3533 - lr: 6.8014e-04\n",
            "Epoch 9/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.4848 - accuracy: 0.8033 - val_loss: 1.5873 - val_accuracy: 0.5100 - lr: 6.1212e-04\n",
            "Epoch 10/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.8555"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.3630 - accuracy: 0.8555 - val_loss: 1.3111 - val_accuracy: 0.5033 - lr: 5.5091e-04\n",
            "Epoch 11/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.2954 - accuracy: 0.8892 - val_loss: 0.8188 - val_accuracy: 0.6467 - lr: 4.9582e-04\n",
            "Epoch 12/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9170"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.2269 - accuracy: 0.9170 - val_loss: 1.2822 - val_accuracy: 0.5600 - lr: 4.4624e-04\n",
            "Epoch 13/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9441"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.1628 - accuracy: 0.9441 - val_loss: 0.8517 - val_accuracy: 0.6867 - lr: 4.0161e-04\n",
            "Epoch 14/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9611"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.1133 - accuracy: 0.9611 - val_loss: 0.8405 - val_accuracy: 0.7167 - lr: 3.6145e-04\n",
            "Epoch 15/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.1076 - accuracy: 0.9637 - val_loss: 0.9559 - val_accuracy: 0.6900 - lr: 3.2531e-04\n",
            "Epoch 16/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9774"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0710 - accuracy: 0.9774 - val_loss: 1.0400 - val_accuracy: 0.7167 - lr: 2.9278e-04\n",
            "Epoch 17/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0752 - accuracy: 0.9737 - val_loss: 1.2075 - val_accuracy: 0.7000 - lr: 2.6350e-04\n",
            "Epoch 18/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 40ms/step - loss: 0.0649 - accuracy: 0.9781 - val_loss: 0.8925 - val_accuracy: 0.7367 - lr: 2.3715e-04\n",
            "Epoch 19/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 0.7973 - val_accuracy: 0.7467 - lr: 2.1343e-04\n",
            "Epoch 20/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 40ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 1.1347 - val_accuracy: 0.6733 - lr: 1.9209e-04\n",
            "Epoch 21/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.8975 - val_accuracy: 0.7467 - lr: 1.7288e-04\n",
            "Epoch 22/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0309 - accuracy: 0.9937 - val_loss: 1.1927 - val_accuracy: 0.7400 - lr: 1.5559e-04\n",
            "Epoch 23/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9922"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 0.8198 - val_accuracy: 0.7767 - lr: 1.4003e-04\n",
            "Epoch 24/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 40ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.8872 - val_accuracy: 0.7200 - lr: 1.2603e-04\n",
            "Epoch 25/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9948"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0228 - accuracy: 0.9948 - val_loss: 0.8016 - val_accuracy: 0.7733 - lr: 1.1343e-04\n",
            "Epoch 26/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.8987 - val_accuracy: 0.7733 - lr: 1.0209e-04\n",
            "Epoch 27/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9970"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.7760 - val_accuracy: 0.7633 - lr: 9.1877e-05\n",
            "Epoch 28/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.8613 - val_accuracy: 0.7533 - lr: 8.2689e-05\n",
            "Epoch 29/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.9441 - val_accuracy: 0.7567 - lr: 7.4420e-05\n",
            "Epoch 30/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.7581 - val_accuracy: 0.8033 - lr: 6.6978e-05\n",
            "Epoch 31/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.7808 - val_accuracy: 0.7833 - lr: 6.0280e-05\n",
            "Epoch 32/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.7520 - val_accuracy: 0.8167 - lr: 5.4252e-05\n",
            "Epoch 33/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9970"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.8102 - val_accuracy: 0.7833 - lr: 4.8827e-05\n",
            "Epoch 34/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.8179 - val_accuracy: 0.7800 - lr: 4.3944e-05\n",
            "Epoch 35/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.8104 - val_accuracy: 0.7633 - lr: 3.9550e-05\n",
            "Epoch 36/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.8130 - val_accuracy: 0.7800 - lr: 3.5595e-05\n",
            "Epoch 37/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.7977 - val_accuracy: 0.8067 - lr: 3.2035e-05\n",
            "Epoch 38/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 41ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.8404 - val_accuracy: 0.7800 - lr: 2.8832e-05\n",
            "Epoch 39/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.7940 - val_accuracy: 0.8100 - lr: 2.5949e-05\n",
            "Epoch 40/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.8036 - val_accuracy: 0.8033 - lr: 2.3354e-05\n",
            "Epoch 41/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.8386 - val_accuracy: 0.7900 - lr: 2.1018e-05\n",
            "Epoch 42/60\n",
            "168/169 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.8008 - val_accuracy: 0.7767 - lr: 1.8917e-05\n",
            "Epoch 43/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.8058 - val_accuracy: 0.8000 - lr: 1.7025e-05\n",
            "Epoch 44/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.8313 - val_accuracy: 0.7833 - lr: 1.5322e-05\n",
            "Epoch 45/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.7866 - val_accuracy: 0.7967 - lr: 1.3790e-05\n",
            "Epoch 46/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.7969 - val_accuracy: 0.8067 - lr: 1.2411e-05\n",
            "Epoch 47/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.8003 - val_accuracy: 0.8067 - lr: 1.1170e-05\n",
            "Epoch 48/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.7774 - val_accuracy: 0.8067 - lr: 1.0053e-05\n",
            "Epoch 49/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.7709 - val_accuracy: 0.8067 - lr: 9.0477e-06\n",
            "Epoch 50/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.7724 - val_accuracy: 0.7967 - lr: 8.1430e-06\n",
            "Epoch 51/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 6s 38ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.7720 - val_accuracy: 0.8033 - lr: 7.3287e-06\n",
            "Epoch 52/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.7991 - val_accuracy: 0.8067 - lr: 6.5958e-06\n",
            "Epoch 53/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.7998 - val_accuracy: 0.7967 - lr: 5.9362e-06\n",
            "Epoch 54/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.7963 - val_accuracy: 0.7967 - lr: 5.3426e-06\n",
            "Epoch 55/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.7793 - val_accuracy: 0.8033 - lr: 4.8083e-06\n",
            "Epoch 56/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.8042 - val_accuracy: 0.7967 - lr: 4.3275e-06\n",
            "Epoch 57/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.7623 - val_accuracy: 0.8067 - lr: 3.8948e-06\n",
            "Epoch 58/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.7683 - val_accuracy: 0.8067 - lr: 3.5053e-06\n",
            "Epoch 59/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.7967 - lr: 3.1548e-06\n",
            "Epoch 60/60\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9989"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169/169 [==============================] - 7s 39ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.7828 - val_accuracy: 0.8033 - lr: 2.8393e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc37bf44460>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/audio/model(linguistic.h5')"
      ],
      "metadata": {
        "id": "pzoATpWfm5KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itE3vLe7nTjf",
        "outputId": "2350aa06-8680-42e8-edba-69d59b3cc020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 25ms/step\n",
            "0.8033333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_confu_matrix = confusion_matrix(y_test, predictions)\n",
        "fault_type = ['el','es_fr','no_sv_de_en_nl']\n",
        "plt.figure(1,figsize=(18,8))\n",
        "sns.heatmap(test_confu_matrix, annot= True,fmt = \"d\",\n",
        "xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
        "plt.title('Test Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "mhIDie5-nenT",
        "outputId": "5b1ca74a-14ec-4eb3-bb26-f85ca4a894bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(140.09375, 0.5, 'True')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}