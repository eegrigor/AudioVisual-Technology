{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDFwY5jrCY6N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "import cv2 as cv\n",
        "import scipy as sp\n",
        "import tensorflow as tf\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPujFOhaj4wu",
        "outputId": "7c14083c-3ba7-444e-dd39-a4aafacabd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load filter banks and label them"
      ],
      "metadata": {
        "id": "9YegtnbvOAKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/audio/de_npy.pickle', 'rb') as file:\n",
        "    X = np.array(pickle.load(file)[:250*2])\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/en_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:250*2], axis=0)\n",
        "    y = np.append(y, np.full(500, 0))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/fr_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:250*2], axis=0)\n",
        "    y = np.append(y, np.full(500, 0))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/nl_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:250*2], axis=0)\n",
        "    y = np.append(y, np.full(500, 0))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/el_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:500*2], axis=0)\n",
        "    y = np.append(y, np.full(999, 1))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/es_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:500*2], axis=0)\n",
        "    y = np.append(y, np.full(999, 1))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/no_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:500*2], axis=0)\n",
        "    y = np.append(y, np.full(999, 2))\n",
        "\n",
        "with open('/content/drive/MyDrive/audio/sv_npy.pickle', 'rb') as file:\n",
        "    X = np.append(X, pickle.load(file)[:500*2], axis=0)\n",
        "    y = np.append(y, np.full(999, 2))\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMl-c3BQCkUP",
        "outputId": "16db5c19-bfe5-4811-cd34-0f1f1e36abf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5996, 1000, 40)\n",
            "(5996,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split and shuffle"
      ],
      "metadata": {
        "id": "7_OIHSrKOF_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "X,y = shuffle(X,y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X=[]\n",
        "y=[]"
      ],
      "metadata": {
        "id": "GH2zRgziJMQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model architecture"
      ],
      "metadata": {
        "id": "AK9R7hFGOJEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(7, 7), activation='relu', padding='valid', input_shape=(1000,40,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(64,(5,5), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(256,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Conv2D(512,(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAXTVI5DJRtD",
        "outputId": "ce8b07cd-2057-4f70-b280-ff89a928f0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 994, 34, 32)       1600      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 994, 34, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 497, 17, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 497, 17, 64)       51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 497, 17, 64)      256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 249, 9, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 249, 9, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 249, 9, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 125, 5, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 125, 5, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 125, 5, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 63, 3, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 63, 3, 512)        1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 63, 3, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 32, 2, 512)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32768)            131072    \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               8388864   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,127,747\n",
            "Trainable params: 10,059,715\n",
            "Non-trainable params: 68,032\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training process"
      ],
      "metadata": {
        "id": "Tb_Fx-h3OL-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "adam = Adam()\n",
        "def step_decay(epoch):\n",
        "    # 00158 = 90.4%\n",
        "\tinitial_lrate = 0.00158\n",
        "\tdrop = 0.9\n",
        "\tepochs_drop = 1\n",
        "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "\treturn lrate\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=adam,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "                'model.h5',\n",
        "                monitor='val_accuracy',\n",
        "                verbose=0,\n",
        "                save_best_only=True,\n",
        "                mode='max'\n",
        "                )\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "es = EarlyStopping(monitor='val_loss',mode = 'max', patience=3)\n",
        "model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                epochs=60,\n",
        "                callbacks=[checkpoint, lrate],\n",
        "                verbose=1,\n",
        "                validation_data=(X_test, y_test),\n",
        "                batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COZgsfCCJc9z",
        "outputId": "3f130e71-df75-4f6f-b1c2-8929f8a73e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338/338 [==============================] - 26s 43ms/step - loss: 1.4811 - accuracy: 0.3879 - val_loss: 1.2024 - val_accuracy: 0.4150 - lr: 0.0014\n",
            "Epoch 2/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 1.0832 - accuracy: 0.4978 - val_loss: 1.3172 - val_accuracy: 0.3883 - lr: 0.0013\n",
            "Epoch 3/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.8372 - accuracy: 0.6190 - val_loss: 1.0694 - val_accuracy: 0.5267 - lr: 0.0012\n",
            "Epoch 4/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.6678 - accuracy: 0.7085 - val_loss: 1.4141 - val_accuracy: 0.4350 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.5398 - accuracy: 0.7793 - val_loss: 2.9845 - val_accuracy: 0.3667 - lr: 9.3297e-04\n",
            "Epoch 6/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.4464 - accuracy: 0.8195 - val_loss: 0.7585 - val_accuracy: 0.6750 - lr: 8.3968e-04\n",
            "Epoch 7/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.3668 - accuracy: 0.8571 - val_loss: 1.1992 - val_accuracy: 0.6117 - lr: 7.5571e-04\n",
            "Epoch 8/60\n",
            "338/338 [==============================] - 13s 40ms/step - loss: 0.2905 - accuracy: 0.8907 - val_loss: 0.6552 - val_accuracy: 0.7983 - lr: 6.8014e-04\n",
            "Epoch 9/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.2109 - accuracy: 0.9220 - val_loss: 0.7949 - val_accuracy: 0.7250 - lr: 6.1212e-04\n",
            "Epoch 10/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.1947 - accuracy: 0.9294 - val_loss: 0.4856 - val_accuracy: 0.8350 - lr: 5.5091e-04\n",
            "Epoch 11/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.1437 - accuracy: 0.9477 - val_loss: 0.7592 - val_accuracy: 0.7950 - lr: 4.9582e-04\n",
            "Epoch 12/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.1300 - accuracy: 0.9535 - val_loss: 3.1581 - val_accuracy: 0.7767 - lr: 4.4624e-04\n",
            "Epoch 13/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0950 - accuracy: 0.9683 - val_loss: 1.7991 - val_accuracy: 0.8167 - lr: 4.0161e-04\n",
            "Epoch 14/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 1.3024 - val_accuracy: 0.7333 - lr: 3.6145e-04\n",
            "Epoch 15/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0715 - accuracy: 0.9765 - val_loss: 1.1094 - val_accuracy: 0.7650 - lr: 3.2531e-04\n",
            "Epoch 16/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0584 - accuracy: 0.9779 - val_loss: 1.1241 - val_accuracy: 0.8000 - lr: 2.9278e-04\n",
            "Epoch 17/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0460 - accuracy: 0.9842 - val_loss: 1.4607 - val_accuracy: 0.8050 - lr: 2.6350e-04\n",
            "Epoch 18/60\n",
            "338/338 [==============================] - 14s 40ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 1.0256 - val_accuracy: 0.8400 - lr: 2.3715e-04\n",
            "Epoch 19/60\n",
            "338/338 [==============================] - 13s 40ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.7456 - val_accuracy: 0.8450 - lr: 2.1343e-04\n",
            "Epoch 20/60\n",
            "338/338 [==============================] - 13s 40ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.6280 - val_accuracy: 0.8550 - lr: 1.9209e-04\n",
            "Epoch 21/60\n",
            "338/338 [==============================] - 13s 40ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.7121 - val_accuracy: 0.8700 - lr: 1.7288e-04\n",
            "Epoch 22/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.7891 - val_accuracy: 0.8600 - lr: 1.5559e-04\n",
            "Epoch 23/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.7465 - val_accuracy: 0.8583 - lr: 1.4003e-04\n",
            "Epoch 24/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.5442 - val_accuracy: 0.8800 - lr: 1.2603e-04\n",
            "Epoch 25/60\n",
            "338/338 [==============================] - 13s 40ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.5753 - val_accuracy: 0.8850 - lr: 1.1343e-04\n",
            "Epoch 26/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.7326 - val_accuracy: 0.8733 - lr: 1.0209e-04\n",
            "Epoch 27/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.6319 - val_accuracy: 0.8767 - lr: 9.1877e-05\n",
            "Epoch 28/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.7278 - val_accuracy: 0.8767 - lr: 8.2689e-05\n",
            "Epoch 29/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.5911 - val_accuracy: 0.8733 - lr: 7.4420e-05\n",
            "Epoch 30/60\n",
            "338/338 [==============================] - 14s 40ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.5476 - val_accuracy: 0.8917 - lr: 6.6978e-05\n",
            "Epoch 31/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.5368 - val_accuracy: 0.8900 - lr: 6.0280e-05\n",
            "Epoch 32/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.8106 - val_accuracy: 0.8600 - lr: 5.4252e-05\n",
            "Epoch 33/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.5394 - val_accuracy: 0.8867 - lr: 4.8827e-05\n",
            "Epoch 34/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.5435 - val_accuracy: 0.8950 - lr: 4.3944e-05\n",
            "Epoch 35/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.4770 - val_accuracy: 0.8933 - lr: 3.9550e-05\n",
            "Epoch 36/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.5207 - val_accuracy: 0.8917 - lr: 3.5595e-05\n",
            "Epoch 37/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.7810 - val_accuracy: 0.9000 - lr: 3.2035e-05\n",
            "Epoch 38/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6255 - val_accuracy: 0.9017 - lr: 2.8832e-05\n",
            "Epoch 39/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.6608 - val_accuracy: 0.8967 - lr: 2.5949e-05\n",
            "Epoch 40/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6321 - val_accuracy: 0.9000 - lr: 2.3354e-05\n",
            "Epoch 41/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.5664 - val_accuracy: 0.9033 - lr: 2.1018e-05\n",
            "Epoch 42/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.6331 - val_accuracy: 0.8983 - lr: 1.8917e-05\n",
            "Epoch 43/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.5190 - val_accuracy: 0.8983 - lr: 1.7025e-05\n",
            "Epoch 44/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.6257 - val_accuracy: 0.8983 - lr: 1.5322e-05\n",
            "Epoch 45/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.5562 - val_accuracy: 0.8967 - lr: 1.3790e-05\n",
            "Epoch 46/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6157 - val_accuracy: 0.8933 - lr: 1.2411e-05\n",
            "Epoch 47/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5660 - val_accuracy: 0.8967 - lr: 1.1170e-05\n",
            "Epoch 48/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.5577 - val_accuracy: 0.8967 - lr: 1.0053e-05\n",
            "Epoch 49/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.5022 - val_accuracy: 0.9050 - lr: 9.0477e-06\n",
            "Epoch 50/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.4942 - val_accuracy: 0.8967 - lr: 8.1430e-06\n",
            "Epoch 51/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.6391 - val_accuracy: 0.8933 - lr: 7.3287e-06\n",
            "Epoch 52/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.6742 - val_accuracy: 0.8967 - lr: 6.5958e-06\n",
            "Epoch 53/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.5888 - val_accuracy: 0.8983 - lr: 5.9362e-06\n",
            "Epoch 54/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.5663 - val_accuracy: 0.8983 - lr: 5.3426e-06\n",
            "Epoch 55/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6044 - val_accuracy: 0.8967 - lr: 4.8083e-06\n",
            "Epoch 56/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.6146 - val_accuracy: 0.8983 - lr: 4.3275e-06\n",
            "Epoch 57/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.6440 - val_accuracy: 0.8983 - lr: 3.8948e-06\n",
            "Epoch 58/60\n",
            "338/338 [==============================] - 13s 39ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.5762 - val_accuracy: 0.9000 - lr: 3.5053e-06\n",
            "Epoch 59/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.5549 - val_accuracy: 0.9000 - lr: 3.1548e-06\n",
            "Epoch 60/60\n",
            "338/338 [==============================] - 13s 38ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.5958 - val_accuracy: 0.8967 - lr: 2.8393e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22e023e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/audio/model(3_class([de,en,fr,nl] ,[el,es], [no,sv])).h5')"
      ],
      "metadata": {
        "id": "_tvfDA8lMTWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and confusion matrix"
      ],
      "metadata": {
        "id": "g-KZ3zDSOUpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.argmax(model.predict(X_test), axis=1)\n"
      ],
      "metadata": {
        "id": "H7x1xEz6Mg1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "test_confu_matrix = confusion_matrix(y_test, predictions)\n",
        "fault_type = ['de_en_nl_fr','el_es','no_sv']\n",
        "plt.figure(1,figsize=(18,8))\n",
        "sns.heatmap(test_confu_matrix, annot= True,fmt = \"d\",\n",
        "xticklabels=fault_type, yticklabels=fault_type, cmap = \"Blues\", cbar = False)\n",
        "plt.title('Test Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "sklearn.metrics.accuracy_score(predictions, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "6OENChQHMlN0",
        "outputId": "8f09df6a-2f35-492c-f53b-1469468ae862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8966666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uy4cCuXUntsX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}